{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "\n",
    "In this notebook the insights gained from exploratory analysis are used to help answer the question around proper stocking requirements for Divvy stations. The goal was to create a model to predict the ratio of trips in / trips out of any given station by day of the week and month of the year. This would allow Divvy to compare this predicted ratio with the current stocking status of their stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Divvy_data_2017T2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'start_station_trip_count': 'start_trips_whole_year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.start_time = pd.to_datetime(df.start_time, format='%Y-%m-%d  %H:%M:%S')\n",
    "df = df.set_index('start_time')\n",
    "df['month_of_year'] = df.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to define our target and predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the number of trips leaving each station by day of the week and month of the year\n",
    "stations_out = df.groupby(['start_station_id', 'day_of_week', 'month_of_year']).count()\n",
    "\n",
    "#Not all stations had trips arrive at them every single day of the year. These are not currently shown as empty values, data does\n",
    "#not appear for those days at all. Unstack the month and day of week, to view information for all days, and fill NaN's with 0's.\n",
    "out = stations_out.unstack(['month_of_year', 'day_of_week'])\n",
    "out = out.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">trip_id</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">week_of_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_of_year</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>273</td>\n",
       "      <td>322</td>\n",
       "      <td>536</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>293</td>\n",
       "      <td>286</td>\n",
       "      <td>463</td>\n",
       "      <td>749</td>\n",
       "      <td>357</td>\n",
       "      <td>623</td>\n",
       "      <td>162</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>171</td>\n",
       "      <td>107</td>\n",
       "      <td>228</td>\n",
       "      <td>556</td>\n",
       "      <td>477</td>\n",
       "      <td>912</td>\n",
       "      <td>682</td>\n",
       "      <td>614</td>\n",
       "      <td>394</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>585</td>\n",
       "      <td>760</td>\n",
       "      <td>876</td>\n",
       "      <td>1248</td>\n",
       "      <td>796</td>\n",
       "      <td>1020</td>\n",
       "      <td>631</td>\n",
       "      <td>188</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>28</td>\n",
       "      <td>182</td>\n",
       "      <td>469</td>\n",
       "      <td>399</td>\n",
       "      <td>744</td>\n",
       "      <td>377</td>\n",
       "      <td>431</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>505</td>\n",
       "      <td>595</td>\n",
       "      <td>867</td>\n",
       "      <td>1052</td>\n",
       "      <td>595</td>\n",
       "      <td>635</td>\n",
       "      <td>369</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>124</td>\n",
       "      <td>147</td>\n",
       "      <td>231</td>\n",
       "      <td>138</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>89</td>\n",
       "      <td>156</td>\n",
       "      <td>197</td>\n",
       "      <td>99</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>54</td>\n",
       "      <td>443</td>\n",
       "      <td>398</td>\n",
       "      <td>655</td>\n",
       "      <td>420</td>\n",
       "      <td>417</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>404</td>\n",
       "      <td>557</td>\n",
       "      <td>834</td>\n",
       "      <td>1038</td>\n",
       "      <td>759</td>\n",
       "      <td>745</td>\n",
       "      <td>442</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 trip_id                                              ...   \\\n",
       "month_of_year         1    2    3    4    5    6    7    8    9    10 ...    \n",
       "day_of_week            0    0    0    0    0    0    0    0    0    0 ...    \n",
       "start_station_id                                                      ...    \n",
       "2                     12   75   51  128  273  322  536  270  330  145 ...    \n",
       "3                     38  171  107  228  556  477  912  682  614  394 ...    \n",
       "4                     15  101   28  182  469  399  744  377  431  251 ...    \n",
       "5                     24   51   35   60  124  147  231  138   95  113 ...    \n",
       "6                     21   99   41   54  443  398  655  420  417  316 ...    \n",
       "\n",
       "                 week_of_year                                                 \n",
       "month_of_year              3    4    5    6     7    8     9    10   11   12  \n",
       "day_of_week                 6    6    6    6     6    6     6    6    6    6  \n",
       "start_station_id                                                              \n",
       "2                          57  293  286  463   749  357   623  162   20   11  \n",
       "3                         186  585  760  876  1248  796  1020  631  188  113  \n",
       "4                          74  505  595  867  1052  595   635  369   76   56  \n",
       "5                          16   63   89  156   197   99    94   89   17   12  \n",
       "6                         119  404  557  834  1038  759   745  442   66   69  \n",
       "\n",
       "[5 rows x 2184 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restack the day and month so we can see the number of trips broken down by these variables with the 0s filled in \n",
    "a = out.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the number of trips arriving at each station by day of the week and month of the year\n",
    "stations_in = df.groupby(['end_station_id', 'day_of_week', 'month_of_year']).count()\n",
    "\n",
    "#Not all stations had trips leave from them every single day of the year. These are not currently shown as empty values, data does\n",
    "#not appear for those days at all. Unstack the month and day of week, to view information for all days, and fill NaN's with 0's.\n",
    "ins = stations_in.unstack(['month_of_year', 'day_of_week'])\n",
    "ins = ins.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#restack the day and month so we can see the number of trips broken down by these variables with the 0s filled in \n",
    "b = ins.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the trips coming in to trips going out ratio for each station\n",
    "def io_ratio():\n",
    "    station_ios = []\n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "        if int(a.trip_id.iloc[row]) == 0 & int(b.trip_id.iloc[row]) == 0:\n",
    "            station_ios.append(1)\n",
    "        elif b.trip_id.iloc[row] == 0:\n",
    "            station_ios.append(1/a.trip_id.iloc[row])\n",
    "        elif a.trip_id.iloc[row] == 0:\n",
    "            station_ios.append(b.trip_id.iloc[row])\n",
    "        else:\n",
    "            io = float(b.trip_id.iloc[row]) / a.trip_id.iloc[row]\n",
    "            station_ios.append(io)\n",
    "    \n",
    "    return station_ios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = io_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the number of trips coming in and coming out of each station by day of the week and month.\n",
    "def rides():\n",
    "    rides_in = []\n",
    "    rides_out =[]\n",
    "    \n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "            rides_in.append(b.trip_id.iloc[row])\n",
    "            rides_out.append(a.trip_id.iloc[row])\n",
    "    \n",
    "    return rides_in, rides_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i, o = rides()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_duration = df.groupby(['start_station_id', 'day_of_week', 'month_of_year']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dur = avg_duration.unstack(['month_of_year', 'day_of_week'])\n",
    "dur = dur.fillna(0)\n",
    "ad = dur.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the number average duration starting from each station by day of the week and month.\n",
    "def average_duration():\n",
    "    avgdur = []\n",
    "    \n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "            avgdur.append(ad.trip_duration.iloc[row])\n",
    "    \n",
    "    return avgdur\n",
    "\n",
    "avgdur = average_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = a.reset_index()\n",
    "c['ratio'] = ratio\n",
    "c['rides_in'] = i\n",
    "c['rides_out'] = o\n",
    "c['average_duration'] = avgdur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add some additional features\n",
    "add_features = df.groupby(['start_station_id', 'start_capacity', 'group', 'start_latitude', 'start_longitude' ]).count()\n",
    "add_features = add_features.reset_index()\n",
    "add_features = add_features[['start_station_id', 'start_capacity', 'group', 'start_latitude', 'start_longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "af = c.merge(add_features, on='start_station_id')\n",
    "c['capacity'] = af.start_capacity_y\n",
    "c['group'] = af.group_y\n",
    "c['latitude'] = af.start_latitude_y\n",
    "c['longitude'] = af.start_longitude_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c['start_station_id'] = c['start_station_id'].astype(float)\n",
    "c['day_of_week'] = c['day_of_week'].astype(float)\n",
    "c['month_of_year'] = c['month_of_year'].astype(float)\n",
    "c['rides_in'] = c['rides_in'].astype(float)\n",
    "c['rides_out'] = c['rides_out'].astype(float)\n",
    "c['capacity'] = c['capacity'].astype(float)\n",
    "c['group'] = c['group'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = c[['start_station_id','day_of_week','month_of_year', 'capacity', 'group','latitude', 'longitude', 'average_duration', \\\n",
    "              'rides_in', 'rides_out', 'ratio',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49140 entries, 0 to 49139\n",
      "Data columns (total 11 columns):\n",
      "start_station_id    49140 non-null float64\n",
      "day_of_week         49140 non-null float64\n",
      "month_of_year       49140 non-null float64\n",
      "capacity            49140 non-null float64\n",
      "group               49140 non-null float64\n",
      "latitude            49140 non-null float64\n",
      "longitude           49140 non-null float64\n",
      "average_duration    49140 non-null float64\n",
      "rides_in            49140 non-null float64\n",
      "rides_out           49140 non-null float64\n",
      "ratio               49140 non-null float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target variable\n",
    "y = data['ratio'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictor variables\n",
    "X = data[['start_station_id', 'day_of_week', 'month_of_year', 'average_duration', 'capacity', 'group', \\\n",
    "         'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.3062231e-05, -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "\n",
    "lasso_coef = lasso.fit(X_train,y_train).coef_\n",
    "\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#station_id was the only coefficent that was not taken down to 0 by lasso. We'll use this along with \n",
    "#day of the week and month of the year to build our model.\n",
    "\n",
    "X =data[['start_station_id', 'day_of_week', 'month_of_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\pandas\\core\\generic.py:2387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#prep categorical variables to utilize the get_dummies function\n",
    "X.start_station_id = X.start_station_id.astype('category')\n",
    "X.month_of_year = X.month_of_year.astype('category')\n",
    "X.day_of_week = X.day_of_week.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have our predictor and target variables, we can split the data into training and tests sets, and train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060308809223191935\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('reg', LinearRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "reg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred= pipeline.predict(X_test)\n",
    "\n",
    "print pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=.5, normalize=True))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'ridge__alpha': [.1,.5,1,5,10]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06402091004585908\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=.1, normalize=True))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "reg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred= pipeline.predict(X_test)\n",
    "\n",
    "print pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What if we separated out the target variable into classes that can be used for different stocking recommendations, and used our data for classification?\n",
    "\n",
    "These stocking classes will be based on the trips in to trips out ratio, and will be separated in a way that a different recommendation can be made about stocking requirements for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njUpiiYiIRiWxREREo5JYIiKiUf8fhmhAtvwy30IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3cdf7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view the distribution for the ratios - most seem to fall between 0 and 2\n",
    "plt.hist(data.ratio)\n",
    "plt.xlabel('Trips in vs trips out ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Ratios')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate the stock classes - different ratios would require different degrees of stocking needs\n",
    "\n",
    "stockclass= []\n",
    "\n",
    "def separate_stockclass():\n",
    "    for i in range(len(c.ratio)):\n",
    "        if c.ratio[i] < .75:\n",
    "            stockclass.append('0 to .75')\n",
    "        #elif c.ratio[i] < .8:\n",
    "        #    stockclass.append('.6 to .9')\n",
    "        elif c.ratio[i] < 1.4:\n",
    "            stockclass.append('.75 to 1.4')\n",
    "        elif c.ratio[i] < 2.5:\n",
    "            stockclass.append('1.2 to 2')\n",
    "        elif c.ratio[i] >= 2.5:\n",
    "            stockclass.append('2.5+')\n",
    "        else:\n",
    "            return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separate_stockclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#new predictor and target variables for classification\n",
    "data['class'] = stockclass\n",
    "y1 = data['class']\n",
    "X1 = data[['start_station_id', 'day_of_week', 'month_of_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 23}\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(9,25)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8259055759055759\n",
      "Test score:  0.8215303215303216\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " .75 to 1.4       0.82      1.00      0.90      8074\n",
      "   0 to .75       0.30      0.01      0.03       973\n",
      "   1.2 to 2       0.67      0.02      0.03       660\n",
      "       2.5+       0.00      0.00      0.00       121\n",
      "\n",
      "avg / total       0.75      0.82      0.75      9828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 24)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 6}\n",
      "0.7559523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9870522995522996\n",
      "Test score:  0.7380952380952381\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " .75 to 1.4       0.85      0.87      0.86      8136\n",
      "   0 to .75       0.14      0.13      0.13       934\n",
      "   1.2 to 2       0.11      0.09      0.10       651\n",
      "       2.5+       0.01      0.01      0.01       107\n",
      "\n",
      "avg / total       0.72      0.74      0.73      9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=.2, random_state=18)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 3}\n",
      "0.8262362637362637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8266178266178266\n",
      "Test score:  0.8269230769230769\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " .75 to 1.4       0.83      1.00      0.91      8086\n",
      "   0 to .75       0.60      0.07      0.13       965\n",
      "   1.2 to 2       0.65      0.02      0.04       661\n",
      "       2.5+       0.00      0.00      0.00       116\n",
      "\n",
      "avg / total       0.79      0.83      0.76      9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y1, test_size=.2, random_state=15, stratify=y1)\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
