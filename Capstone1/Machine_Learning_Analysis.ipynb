{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "\n",
    "In this notebook the insights gained from exploratory analysis are used to help answer the question surrounding proper stocking requirements for Divvy stations. The goal was to create a model to predict the ratio of trips in / trips out of any given station by day of the week and month of the year. This would allow Divvy to compare this predicted ratio with the current stocking status of their stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Divvy_data_2017T2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'start_station_trip_count': 'start_trips_whole_year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.start_time = pd.to_datetime(df.start_time, format='%Y-%m-%d  %H:%M:%S')\n",
    "df = df.set_index('start_time')\n",
    "df['month_of_year'] = df.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to define our target and predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the number of trips leaving each station by day of the week and month of the year\n",
    "stations_out = df.groupby(['start_station_id', 'day_of_week', 'month_of_year']).count()\n",
    "\n",
    "#Not all stations had trips arrive at them every single day of the year. These are not currently shown as empty values, data does\n",
    "#not appear for those days at all. Unstack the month and day of week, to view information for all days, and fill NaN's with 0's.\n",
    "out = stations_out.unstack(['month_of_year', 'day_of_week'])\n",
    "out = out.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">trip_id</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">week_of_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_of_year</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>273</td>\n",
       "      <td>322</td>\n",
       "      <td>536</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>293</td>\n",
       "      <td>286</td>\n",
       "      <td>463</td>\n",
       "      <td>749</td>\n",
       "      <td>357</td>\n",
       "      <td>623</td>\n",
       "      <td>162</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>171</td>\n",
       "      <td>107</td>\n",
       "      <td>228</td>\n",
       "      <td>556</td>\n",
       "      <td>477</td>\n",
       "      <td>912</td>\n",
       "      <td>682</td>\n",
       "      <td>614</td>\n",
       "      <td>394</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>585</td>\n",
       "      <td>760</td>\n",
       "      <td>876</td>\n",
       "      <td>1248</td>\n",
       "      <td>796</td>\n",
       "      <td>1020</td>\n",
       "      <td>631</td>\n",
       "      <td>188</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>28</td>\n",
       "      <td>182</td>\n",
       "      <td>469</td>\n",
       "      <td>399</td>\n",
       "      <td>744</td>\n",
       "      <td>377</td>\n",
       "      <td>431</td>\n",
       "      <td>251</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>505</td>\n",
       "      <td>595</td>\n",
       "      <td>867</td>\n",
       "      <td>1052</td>\n",
       "      <td>595</td>\n",
       "      <td>635</td>\n",
       "      <td>369</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>124</td>\n",
       "      <td>147</td>\n",
       "      <td>231</td>\n",
       "      <td>138</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>89</td>\n",
       "      <td>156</td>\n",
       "      <td>197</td>\n",
       "      <td>99</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>54</td>\n",
       "      <td>443</td>\n",
       "      <td>398</td>\n",
       "      <td>655</td>\n",
       "      <td>420</td>\n",
       "      <td>417</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>404</td>\n",
       "      <td>557</td>\n",
       "      <td>834</td>\n",
       "      <td>1038</td>\n",
       "      <td>759</td>\n",
       "      <td>745</td>\n",
       "      <td>442</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 trip_id                                              ...   \\\n",
       "month_of_year         1    2    3    4    5    6    7    8    9    10 ...    \n",
       "day_of_week            0    0    0    0    0    0    0    0    0    0 ...    \n",
       "start_station_id                                                      ...    \n",
       "2                     12   75   51  128  273  322  536  270  330  145 ...    \n",
       "3                     38  171  107  228  556  477  912  682  614  394 ...    \n",
       "4                     15  101   28  182  469  399  744  377  431  251 ...    \n",
       "5                     24   51   35   60  124  147  231  138   95  113 ...    \n",
       "6                     21   99   41   54  443  398  655  420  417  316 ...    \n",
       "\n",
       "                 week_of_year                                                 \n",
       "month_of_year              3    4    5    6     7    8     9    10   11   12  \n",
       "day_of_week                 6    6    6    6     6    6     6    6    6    6  \n",
       "start_station_id                                                              \n",
       "2                          57  293  286  463   749  357   623  162   20   11  \n",
       "3                         186  585  760  876  1248  796  1020  631  188  113  \n",
       "4                          74  505  595  867  1052  595   635  369   76   56  \n",
       "5                          16   63   89  156   197   99    94   89   17   12  \n",
       "6                         119  404  557  834  1038  759   745  442   66   69  \n",
       "\n",
       "[5 rows x 2184 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restack the day and month so we can see the number of trips broken down by these variables with the 0s filled in \n",
    "a = out.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the number of trips arriving at each station by day of the week and month of the year\n",
    "stations_in = df.groupby(['end_station_id', 'day_of_week', 'month_of_year']).count()\n",
    "\n",
    "#Not all stations had trips leave from them every single day of the year. These are not currently shown as empty values, data does\n",
    "#not appear for those days at all. Unstack the month and day of week, to view information for all days, and fill NaN's with 0's.\n",
    "ins = stations_in.unstack(['month_of_year', 'day_of_week'])\n",
    "ins = ins.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#restack the day and month so we can see the number of trips broken down by these variables with the 0s filled in \n",
    "b = ins.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the trips coming in to trips going out ratio for each station\n",
    "def io_ratio():\n",
    "    station_ios = []\n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "        if int(a.trip_id.iloc[row]) == 0 & int(b.trip_id.iloc[row]) == 0:\n",
    "            station_ios.append(1)\n",
    "        elif b.trip_id.iloc[row] == 0:\n",
    "            station_ios.append(1/a.trip_id.iloc[row])\n",
    "        elif a.trip_id.iloc[row] == 0:\n",
    "            station_ios.append(b.trip_id.iloc[row])\n",
    "        else:\n",
    "            io = float(b.trip_id.iloc[row]) / a.trip_id.iloc[row]\n",
    "            station_ios.append(io)\n",
    "    \n",
    "    return station_ios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = io_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the number of trips coming in and coming out of each station by day of the week and month.\n",
    "def rides():\n",
    "    rides_in = []\n",
    "    rides_out =[]\n",
    "    \n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "            rides_in.append(b.trip_id.iloc[row])\n",
    "            rides_out.append(a.trip_id.iloc[row])\n",
    "    \n",
    "    return rides_in, rides_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i, o = rides()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_duration = df.groupby(['start_station_id', 'day_of_week', 'month_of_year']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dur = avg_duration.unstack(['month_of_year', 'day_of_week'])\n",
    "dur = dur.fillna(0)\n",
    "ad = dur.stack(['day_of_week', 'month_of_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to find the number average duration starting from each station by day of the week and month.\n",
    "def average_duration():\n",
    "    avgdur = []\n",
    "    \n",
    "    \n",
    "    #49140 is how many observations there our in our data broken down by station, day of week, and month of the year\n",
    "    for row in range(0, 49140):\n",
    "            avgdur.append(ad.trip_duration.iloc[row])\n",
    "    \n",
    "    return avgdur\n",
    "\n",
    "avgdur = average_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = a.reset_index()\n",
    "c['ratio'] = ratio\n",
    "c['rides_in'] = i\n",
    "c['rides_out'] = o\n",
    "c['average_duration'] = avgdur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add some additional features\n",
    "add_features = df.groupby(['start_station_id', 'start_capacity', 'group', 'start_latitude', 'start_longitude' ]).count()\n",
    "add_features = add_features.reset_index()\n",
    "add_features = add_features[['start_station_id', 'start_capacity', 'group', 'start_latitude', 'start_longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "af = c.merge(add_features, on='start_station_id')\n",
    "c['capacity'] = af.start_capacity_y\n",
    "c['group'] = af.group_y\n",
    "c['latitude'] = af.start_latitude_y\n",
    "c['longitude'] = af.start_longitude_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c['start_station_id'] = c['start_station_id'].astype(float)\n",
    "c['day_of_week'] = c['day_of_week'].astype(float)\n",
    "c['month_of_year'] = c['month_of_year'].astype(float)\n",
    "c['rides_in'] = c['rides_in'].astype(float)\n",
    "c['rides_out'] = c['rides_out'].astype(float)\n",
    "c['capacity'] = c['capacity'].astype(float)\n",
    "c['group'] = c['group'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = c[['start_station_id','day_of_week','month_of_year', 'capacity', 'group','latitude', 'longitude', 'average_duration', \\\n",
    "              'rides_in', 'rides_out', 'ratio',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.886922999999996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.latitude.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.65383299999998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.longitude.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sections = []\n",
    "\n",
    "for i in data['latitude']:\n",
    "    if i >= 41.886923:\n",
    "        sections.append(1)\n",
    "    else:\n",
    "        sections.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data['section'] = sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "territory = []\n",
    "\n",
    "north = data.loc[data.section ==1]\n",
    "south = data.loc[data.section ==0]\n",
    "\n",
    "for i in north['longitude']:\n",
    "    if i < -87.653833:\n",
    "        territory.append(1)\n",
    "    else:\n",
    "        territory.append(2)\n",
    "        \n",
    "for i in south['longitude']:\n",
    "    if i < -87.653833:\n",
    "        territory.append(3)\n",
    "    else:\n",
    "        territory.append(4)\n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data['territory'] = territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#add in the date when the bike stations went live\n",
    "\n",
    "online = df[['start_station_id','start_online_date']]\n",
    "online1 = online.drop_duplicates('start_station_id')\n",
    "online1['start_online_date'] = pd.to_datetime(online1['start_online_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_online_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-31 22:52:02</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-10 10:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31 17:19:34</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-06-10 10:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31 19:13:42</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-06-10 10:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31 22:37:14</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-06-10 10:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31 20:16:59</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-10 11:18:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     start_station_id   start_online_date\n",
       "start_time                                               \n",
       "2017-03-31 22:52:02                 2 2013-06-10 10:43:00\n",
       "2017-03-31 17:19:34                 3 2013-06-10 10:44:00\n",
       "2017-03-31 19:13:42                 4 2013-06-10 10:46:00\n",
       "2017-03-31 22:37:14                 5 2013-06-10 10:46:00\n",
       "2017-03-31 20:16:59                 6 2013-06-10 11:18:00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online1 = online1.sort_values('start_station_id')\n",
    "online1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = []\n",
    "for i in range(0,585):\n",
    "    years.append(online1.start_online_date[i].year)\n",
    "    \n",
    "online1['year_online'] = years\n",
    "\n",
    "months = []\n",
    "\n",
    "for i in range(0,585):\n",
    "    months.append(online1.start_online_date[i].month)\n",
    "    \n",
    "online1['month_online'] = months\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "online_dates = online1[['start_station_id', 'year_online', 'month_online']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.merge(online_dates, on='start_station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49140.000000\n",
       "mean        17.507692\n",
       "std          6.670351\n",
       "min         11.000000\n",
       "25%         15.000000\n",
       "50%         15.000000\n",
       "75%         19.000000\n",
       "max         55.000000\n",
       "Name: capacity, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group stations by capacities\n",
    "data.capacity.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capgs = []\n",
    "\n",
    "for i in data['capacity']:\n",
    "    if i < 15:\n",
    "        capgs.append(1)\n",
    "    elif i == 15:\n",
    "        capgs.append(2)\n",
    "    elif i < 20:\n",
    "        capgs.append(3)\n",
    "    elif i >= 20:\n",
    "        capgs.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['cap_group'] = capgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict the stocking ratio for all stations it may be helpful to segment the stations into groups and train models for each groups intricacies. Here we'll group stations based on their size using the cap_group designations.\n",
    "\n",
    "In past analysis we've found that the average ratio between stations capacities does not differ significantly but the variance is much higher for the lower capacity stations. Grouping in this way will also help predict the ratio for new stations. (If we grouped by traffic level for instatnce, we would not have any trip information for a brand new station to place it correctly.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group1 = data.loc[data.cap_group == 1]\n",
    "Xg1 = group1[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'section', 'year_online','month_online', 'group']]\n",
    "yg1 = group1['ratio']\n",
    "\n",
    "group2 = data.loc[data.cap_group == 2]\n",
    "Xg2 = group2[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'section', 'year_online','month_online', 'group']]\n",
    "yg2 = group2['ratio']\n",
    "\n",
    "group3 = data.loc[data.cap_group == 3]\n",
    "Xg3 = group3[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'section', 'year_online','month_online', 'group']]\n",
    "yg3 = group3['ratio']\n",
    "\n",
    "group4 = data.loc[data.cap_group == 4]\n",
    "Xg4 = group4[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'section', 'year_online','month_online', 'group']]\n",
    "yg4 = group4['ratio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictor variables\n",
    "X = data[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'section', 'year_online','month_online', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target variable\n",
    "y = data['ratio'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "\n",
    "lasso_coef = lasso.fit(X_train,y_train).coef_\n",
    "\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "None of the variables have strong coefficents, so we will use all predictor varibles while creating our models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\pandas\\core\\generic.py:2387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#prep categorical variables to utilize the get_dummies function\n",
    "X.group = X.group.astype('category')\n",
    "X.month_of_year = X.month_of_year.astype('category')\n",
    "X.day_of_week = X.day_of_week.astype('category')\n",
    "X.section = X.section.astype(\"category\")\n",
    "X.territory = X.territory.astype('category')\n",
    "\n",
    "Xg1.group = X.group.astype('category')\n",
    "Xg1.month_of_year = X.month_of_year.astype('category')\n",
    "Xg1.day_of_week = X.day_of_week.astype('category')\n",
    "Xg1.section = X.section.astype(\"category\")\n",
    "Xg1.territory = X.territory.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "Xg1 = pd.get_dummies(Xg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will also need a baseline to compare our model against later on\n",
    "\n",
    "This will allow us to see how well our models compare against just using the average ratio for each station for the year as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count number of rides out per station for 2017\n",
    "rout = df.groupby(['start_station_id']).count()\n",
    "\n",
    "#count number of rides in per station for 2017\n",
    "rin = df.groupby(['end_station_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the infromation for trips in and trips out ready for a join\n",
    "i = pd.DataFrame(rin.trip_id)\n",
    "o = pd.DataFrame(rout.trip_id)\n",
    "i.rename(columns={'trip_id': 'trips_in'}, inplace=True)\n",
    "o.rename(columns={'trip_id': 'trips_out'}, inplace=True)\n",
    "i.index.names = ['station_id']\n",
    "o.index.names= ['station_id']\n",
    "\n",
    "# join trips in and out into one dataframe\n",
    "io = i.join(o, how='outer')\n",
    "io['2017_ratio'] = io.trips_in / io.trips_out\n",
    "\n",
    "io = io.drop(['trips_in', 'trips_out'], axis=1)\n",
    "io = io.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.merge(io, left_on='start_station_id', right_on='station_id')\n",
    "data = data.drop('station_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have our predictor and target variables, we can split the data into training and tests sets, and train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009087623565337544\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('reg', LinearRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=15)\n",
    "reg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred= pipeline.predict(X_test)\n",
    "\n",
    "print pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026512744618963913\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('reg', LinearRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xg1, yg1, test_size=.2, random_state=15)\n",
    "reg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred= pipeline.predict(X_test)\n",
    "\n",
    "print pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=.5, normalize=True))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'ridge__alpha': [.1,.5,1,5,10]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xg1, yg1, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019294830660026019\n"
     ]
    }
   ],
   "source": [
    "steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=.1, normalize=True))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xg1, yg1, test_size=.2, random_state=15)\n",
    "reg_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred= pipeline.predict(X_test)\n",
    "\n",
    "print pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What if we separated out the target variable into classes that can be used for different stocking recommendations, and used our data for classification?\n",
    "\n",
    "These stocking classes will be based on the trips in to trips out ratio, and will be separated in a way that a different recommendation can be made about stocking requirements for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njUpiiYiIRiWxREREo5JYIiKiUf8fhmhAtvwy30IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cbb2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view the distribution for the ratios - most seem to fall between 0 and 2\n",
    "plt.hist(data.ratio)\n",
    "plt.xlabel('Trips in vs trips out ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Ratios')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate the stock classes - different ratios would require different degrees of stocking needs\n",
    "\n",
    "stockclass= []\n",
    "\n",
    "def separate_stockclass():\n",
    "    for i in range(len(c.ratio)):\n",
    "        if data.ratio[i] < .5:\n",
    "            stockclass.append('0 to .5')\n",
    "        elif data.ratio[i] < .8:\n",
    "            stockclass.append('.5 to .8')\n",
    "        elif data.ratio[i] < 1.2:\n",
    "            stockclass.append('.8 to 1.2')\n",
    "        elif data.ratio[i] < 2.5:\n",
    "            stockclass.append('1.2 to 2.5')\n",
    "        elif data.ratio[i] >= 2.5:\n",
    "            stockclass.append('2.5+')\n",
    "        else:\n",
    "            return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separate_stockclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new predictor and target variables for classification\n",
    "data['class'] = stockclass\n",
    "yc = data['class']\n",
    "Xc = data[['day_of_week', 'month_of_year', 'average_duration', 'group', 'capacity', 'territory', 'year_online', 'month_online', 'section']]\n",
    "\n",
    "#update the grouped predictor and target variables\n",
    "g1c = group1[['day_of_week', 'month_of_year', 'average_duration', 'group', 'capacity', 'territory', 'year_online', 'month_online', 'section']]\n",
    "g1yc = data['class'].loc[data.cap_group == 1]\n",
    "g2c = group2[['day_of_week', 'month_of_year', 'average_duration', 'group', 'capacity', 'territory', 'year_online', 'month_online', 'section']]\n",
    "g2yc = data['class'].loc[data.cap_group == 2]\n",
    "g3c = group3[['day_of_week', 'month_of_year', 'average_duration', 'group', 'capacity', 'territory', 'year_online', 'month_online', 'section']]\n",
    "g3yc = data['class'].loc[data.cap_group == 3]\n",
    "g4c = group4[['day_of_week', 'month_of_year', 'average_duration', 'capacity', 'territory', 'year_online', 'month_online', 'group', 'section']]\n",
    "g4yc = data['class'].loc[data.cap_group == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create benchmarks to help evaluate our models going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at baseline performance for these new classes. As mentioned previously the average ratio per station for the year will act\n",
    "#as our benchmark\n",
    "baseline_results= []\n",
    "\n",
    "def baseline():\n",
    "    for i in range(len(c.ratio)):\n",
    "        if data['2017_ratio'][i] < .5:\n",
    "            baseline_results.append('0 to .5')\n",
    "        elif data['2017_ratio'][i] < .8:\n",
    "            baseline_results.append('.5 to .8')\n",
    "        elif data['2017_ratio'][i] < 1.2:\n",
    "            baseline_results.append('.8 to 1.2')\n",
    "        elif data['2017_ratio'][i] < 2.5:\n",
    "            baseline_results.append('1.2 to 2.5')\n",
    "        elif data['2017_ratio'][i] >= 2.5:\n",
    "            baseline_results.append('2.5+')\n",
    "        else:\n",
    "            return 'Error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline()\n",
    "data['baseline'] = baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the grouped dfs to include the class and baseline variables\n",
    "group1 = data.loc[data.cap_group == 1]\n",
    "group2 = data.loc[data.cap_group == 2]\n",
    "group3 = data.loc[data.cap_group == 3]\n",
    "group4 = data.loc[data.cap_group == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6846764346764347"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline performance for non-group model\n",
    "a = data['class'].loc[data['class'] == data['baseline']]\n",
    "float(len(a))/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.23      0.06      0.10      5502\n",
      "  .8 to 1.2       0.72      0.94      0.81     34657\n",
      "    0 to .5       0.24      0.02      0.04       919\n",
      " 1.2 to 2.5       0.34      0.09      0.15      7482\n",
      "       2.5+       0.05      0.01      0.01       580\n",
      "\n",
      "avg / total       0.59      0.68      0.61     49140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(data['class'], data['baseline'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6102292768959435"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline performance for group1\n",
    "a = group1['class'].loc[group1['class'] == group1['baseline']]\n",
    "float(len(a))/len(group1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.15      0.10      0.12      1115\n",
      "  .8 to 1.2       0.71      0.83      0.77      6308\n",
      "    0 to .5       0.00      0.00      0.00       315\n",
      " 1.2 to 2.5       0.19      0.14      0.16      1129\n",
      "       2.5+       0.05      0.02      0.03       205\n",
      "\n",
      "avg / total       0.54      0.61      0.57      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(group1['class'], group1['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6367426347971095"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline performance for group2\n",
    "a = group2['class'].loc[group2['class'] == group2['baseline']]\n",
    "float(len(a))/len(group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.10      0.02      0.03      2677\n",
      "  .8 to 1.2       0.66      0.95      0.78     14163\n",
      "    0 to .5       0.24      0.04      0.07       482\n",
      " 1.2 to 2.5       0.37      0.07      0.12      3963\n",
      "       2.5+       0.00      0.00      0.00       303\n",
      "\n",
      "avg / total       0.52      0.64      0.54     21588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(group2['class'], group2['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7470501474926253"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline performance for group3\n",
    "a = group3['class'].loc[group3['class'] == group3['baseline']]\n",
    "float(len(a))/len(group3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.19      0.02      0.03       924\n",
      "  .8 to 1.2       0.76      0.98      0.85      7036\n",
      "    0 to .5       0.00      0.00      0.00        98\n",
      " 1.2 to 2.5       0.59      0.14      0.23      1388\n",
      "       2.5+       0.00      0.00      0.00        46\n",
      "\n",
      "avg / total       0.67      0.75      0.67      9492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(group3['class'], group3['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090787716955942"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline performance for group4\n",
    "a = group4['class'].loc[group4['class'] == group4['baseline']]\n",
    "float(len(a))/len(group4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.19      0.02      0.03       924\n",
      "  .8 to 1.2       0.76      0.98      0.85      7036\n",
      "    0 to .5       0.00      0.00      0.00        98\n",
      " 1.2 to 2.5       0.59      0.14      0.23      1388\n",
      "       2.5+       0.00      0.00      0.00        46\n",
      "\n",
      "avg / total       0.67      0.75      0.67      9492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(group3['class'], group3['baseline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 24}\n",
      "0.7013380138380139\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(9,25)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7117165242165242\n",
      "Test score:  0.7001424501424501\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.26      0.05      0.08      1104\n",
      "  .8 to 1.2       0.72      0.98      0.83      6935\n",
      "    0 to .5       0.00      0.00      0.00       186\n",
      " 1.2 to 2.5       0.31      0.04      0.07      1482\n",
      "       2.5+       0.00      0.00      0.00       121\n",
      "\n",
      "avg / total       0.58      0.70      0.60      9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 24)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 18}\n",
      "0.6745211519911809\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7016673556566074\n",
      "Test score:  0.699724517906336\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.27      0.12      0.17       208\n",
      "  .8 to 1.2       0.74      0.95      0.83      1301\n",
      "    0 to .5       0.00      0.00      0.00        64\n",
      " 1.2 to 2.5       0.23      0.06      0.10       207\n",
      "       2.5+       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.59      0.70      0.63      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 24}\n",
      "0.6479444122756225\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(9,25)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6615518239722061\n",
      "Test score:  0.6387216303844372\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.11      0.01      0.03       564\n",
      "  .8 to 1.2       0.66      0.97      0.78      2808\n",
      "    0 to .5       0.00      0.00      0.00        90\n",
      " 1.2 to 2.5       0.25      0.04      0.07       807\n",
      "       2.5+       0.00      0.00      0.00        49\n",
      "\n",
      "avg / total       0.49      0.64      0.53      4318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 24)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 19}\n",
      "0.7375214012906625\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(9,25)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7445015145528776\n",
      "Test score:  0.7424960505529226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.12      0.01      0.02       187\n",
      "  .8 to 1.2       0.75      0.99      0.85      1414\n",
      "    0 to .5       0.00      0.00      0.00        18\n",
      " 1.2 to 2.5       0.45      0.05      0.09       274\n",
      "       2.5+       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.64      0.74      0.65      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 23)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 22}\n",
      "0.8027816411682893\n"
     ]
    }
   ],
   "source": [
    "steps=[('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'knn__n_neighbors':np.arange(9,25)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8116828929068151\n",
      "Test score:  0.8047830923248054\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.81      0.17      0.28       149\n",
      "  .8 to 1.2       0.81      0.99      0.89      1425\n",
      "    0 to .5       0.00      0.00      0.00         8\n",
      " 1.2 to 2.5       0.42      0.05      0.09       208\n",
      "       2.5+       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.76      0.80      0.74      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors= 14)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 17}\n",
      "0.6654202279202279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danny\\Miniconda2\\envs\\tutorial\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.992979242979243\n",
      "Test score:  0.6696174196174196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.25      0.17      0.20      1104\n",
      "  .8 to 1.2       0.76      0.88      0.82      6935\n",
      "    0 to .5       0.15      0.06      0.09       186\n",
      " 1.2 to 2.5       0.30      0.18      0.23      1482\n",
      "       2.5+       0.09      0.03      0.05       121\n",
      "\n",
      "avg / total       0.61      0.67      0.63      9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 17}\n",
      "0.6442055945983188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9833264434339258\n",
      "Test score:  0.6539944903581267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.24      0.26      0.25       208\n",
      "  .8 to 1.2       0.78      0.83      0.81      1301\n",
      "    0 to .5       0.21      0.12      0.16        64\n",
      " 1.2 to 2.5       0.26      0.19      0.22       207\n",
      "       2.5+       0.06      0.03      0.04        35\n",
      "\n",
      "avg / total       0.63      0.65      0.64      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 16}\n",
      "0.6009264620729589\n"
     ]
    }
   ],
   "source": [
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.986624203821656\n",
      "Test score:  0.5970356646595646\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.21      0.15      0.18       564\n",
      "  .8 to 1.2       0.71      0.83      0.77      2808\n",
      "    0 to .5       0.13      0.07      0.09        90\n",
      " 1.2 to 2.5       0.28      0.21      0.24       807\n",
      "       2.5+       0.04      0.02      0.03        49\n",
      "\n",
      "avg / total       0.55      0.60      0.57      4318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=14)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 17}\n",
      "0.7111813512445674\n"
     ]
    }
   ],
   "source": [
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9924930857368629\n",
      "Test score:  0.7203791469194313\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.25      0.14      0.18       187\n",
      "  .8 to 1.2       0.79      0.91      0.84      1414\n",
      "    0 to .5       0.12      0.06      0.08        18\n",
      " 1.2 to 2.5       0.37      0.19      0.25       274\n",
      "       2.5+       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.66      0.72      0.68      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__n_estimators': 15}\n",
      "0.7934631432545202\n"
     ]
    }
   ],
   "source": [
    "steps=[('rf', RandomForestClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'rf__n_estimators':np.arange(5,20)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9897079276773296\n",
      "Test score:  0.7897664071190211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.59      0.34      0.43       149\n",
      "  .8 to 1.2       0.83      0.94      0.88      1425\n",
      "    0 to .5       0.00      0.00      0.00         8\n",
      " 1.2 to 2.5       0.29      0.13      0.18       208\n",
      "       2.5+       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.74      0.79      0.76      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma=.001, C=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.693399476367645\n",
      "Test score:  0.715702479338843\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.25      0.00      0.01       208\n",
      "  .8 to 1.2       0.72      1.00      0.83      1301\n",
      "    0 to .5       0.00      0.00      0.00        64\n",
      " 1.2 to 2.5       0.00      0.00      0.00       207\n",
      "       2.5+       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.54      0.72      0.60      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma=.001, C=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6594093804284887\n",
      "Test score:  0.6498378879110699\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.00      0.00      0.00       564\n",
      "  .8 to 1.2       0.65      1.00      0.79      2808\n",
      "    0 to .5       0.00      0.00      0.00        90\n",
      " 1.2 to 2.5       0.00      0.00      0.00       807\n",
      "       2.5+       0.00      0.00      0.00        49\n",
      "\n",
      "avg / total       0.42      0.65      0.51      4318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7416041090478072\n",
      "Test score:  0.7446024223275408\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.00      0.00      0.00       187\n",
      "  .8 to 1.2       0.75      1.00      0.85      1414\n",
      "    0 to .5       0.00      0.00      0.00        18\n",
      " 1.2 to 2.5       0.33      0.00      0.01       274\n",
      "       2.5+       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.60      0.74      0.64      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8023643949930459\n",
      "Test score:  0.7975528364849833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.85      0.07      0.14       149\n",
      "  .8 to 1.2       0.80      1.00      0.89      1425\n",
      "    0 to .5       0.00      0.00      0.00         8\n",
      " 1.2 to 2.5       0.00      0.00      0.00       208\n",
      "       2.5+       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.70      0.80      0.71      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 9}\n",
      "0.6517857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6574074074074074\n",
      "Test score:  0.6597476597476597\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.16      0.07      0.10      1104\n",
      "  .8 to 1.2       0.72      0.91      0.80      6935\n",
      "    0 to .5       0.04      0.05      0.05       186\n",
      " 1.2 to 2.5       0.21      0.05      0.08      1482\n",
      "       2.5+       0.00      0.00      0.00       121\n",
      "\n",
      "avg / total       0.56      0.66      0.59      9828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=9)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1cd = pd.get_dummies(g1c)\n",
    "g2cd = pd.get_dummies(g2c)\n",
    "g3cd = pd.get_dummies(g3c)\n",
    "g4cd = pd.get_dummies(g4c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 2}\n",
      "0.605484359928345\n"
     ]
    }
   ],
   "source": [
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1c, g1yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6049331679757476\n",
      "Test score:  0.6038567493112947\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.17      0.15      0.16       208\n",
      "  .8 to 1.2       0.77      0.79      0.78      1301\n",
      "    0 to .5       0.04      0.06      0.05        64\n",
      " 1.2 to 2.5       0.15      0.13      0.14       207\n",
      "       2.5+       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.59      0.60      0.60      1815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g1cd, g1yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 1}\n",
      "0.6160393746381008\n"
     ]
    }
   ],
   "source": [
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2c, g2yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6163867979154604\n",
      "Test score:  0.611162575266327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.19      0.01      0.03       564\n",
      "  .8 to 1.2       0.66      0.92      0.77      2808\n",
      "    0 to .5       0.00      0.00      0.00        90\n",
      " 1.2 to 2.5       0.24      0.04      0.07       807\n",
      "       2.5+       0.02      0.10      0.04        49\n",
      "\n",
      "avg / total       0.50      0.61      0.52      4318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=7)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g2cd, g2yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 7}\n",
      "0.7214539707625445\n"
     ]
    }
   ],
   "source": [
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3c, g3yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.721058870011853\n",
      "Test score:  0.7235387045813586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.00      0.00      0.00       187\n",
      "  .8 to 1.2       0.75      0.97      0.84      1414\n",
      "    0 to .5       0.00      0.00      0.00        18\n",
      " 1.2 to 2.5       0.00      0.00      0.00       274\n",
      "       2.5+       0.03      0.33      0.06         6\n",
      "\n",
      "avg / total       0.56      0.72      0.63      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=7)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g3cd, g3yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNB__alpha': 1}\n",
      "0.7760778859527121\n"
     ]
    }
   ],
   "source": [
    "steps=[('MNB', MultinomialNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'MNB__alpha':np.arange(1,10)}\n",
    "\n",
    "#using X on this model because X has the dummy columns added in\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print cv.best_params_\n",
    "print cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7777468706536856\n",
      "Test score:  0.7725250278086763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   .5 to .8       0.21      0.09      0.12       149\n",
      "  .8 to 1.2       0.79      0.97      0.87      1425\n",
      "    0 to .5       0.00      0.00      0.00         8\n",
      " 1.2 to 2.5       0.00      0.00      0.00       208\n",
      "       2.5+       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.65      0.77      0.70      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(g4c, g4yc, test_size=.2, random_state=15)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print \"Training score: \", clf.score(X_train, y_train)\n",
    "print \"Test score: \", clf.score(X_test, y_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEcCAYAAAAlVNiEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19b7c630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "knn = [70.01,70,63.87,74.24,80.48]\n",
    "\n",
    "svm = [72.69,71.57,64.98,74.46,79.76]\n",
    "\n",
    "randomforest = [66.96,65.4,59.7,72.04,78.98]\n",
    "\n",
    "MNbayes = [65.97,60.39,61.12,72.35,77.25]\n",
    "\n",
    "benchmark = [68.47,61.02,63.67,74.71,80.91]\n",
    "\n",
    "\n",
    "xaxis = [1,2,3,4,5]\n",
    "\n",
    "plt.plot(xaxis, benchmark, marker='.', color='red', label='Benchmark')\n",
    "plt.plot(xaxis, knn, color='green', label='KNN')\n",
    "plt.plot(xaxis, svm, color='blue', label='SVM')\n",
    "plt.plot(xaxis, randomforest, color='yellow', label='Random Forest')\n",
    "plt.plot(xaxis, MNbayes, color='purple', label='MN Bayes')\n",
    "plt.xticks([1, 2, 3, 4, 5], ['U', 1,2,3,4,5])\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Groups')\n",
    "plt.ylabel('Accuracy scores')\n",
    "plt.title('Model Performance by Group')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
